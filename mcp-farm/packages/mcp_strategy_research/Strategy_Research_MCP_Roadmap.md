# ðŸš€ Strategy Research MCP â€” Roadmap & Direction

> **Mission:** Build a reliable â€œdiscover â†’ extract â†’ normalize â†’ backtest â†’ learnâ€ pipeline for TA-driven trading strategies with rock-solid provenance and reproducibility.

---

## ðŸ§­ Guiding Principles

- ðŸ§ª **Provenance-first:** Every artifact is reproducible, cited, and versioned.
- ðŸ“Œ **Span-grounded extraction:** Rules are traceable to exact text spans (no hallucinations).
- ðŸ” **Closed-loop learning:** Backtest results feed search focus, prompts, and ranking.
- ðŸ›¡ï¸ **Politeness & licensing:** Respect robots.txt and document licenses.
- ðŸ§± **Composable MCPs:** Clear boundaries across acquisition, extraction, testing, and orchestration.

---

## ðŸ—ºï¸ Milestones

### 1) Orchestrate & Scale Discovery
- ðŸ§  **LangGraph coordinator** around MCPs (Indicators + Strategy Research; later Backtester/Generator).
- ðŸŒ **Source adapters** beyond arXiv/SSRN/IDEAS: curated blogs (Quantocracy, QuantStart, exchange research), GitHub notes, and conference proceedings.
- ðŸ§¾ **Doc store** with per-doc fingerprint, metadata (license/DOI/source type), and manifest (JSONL/Parquet).
- âš¡ **HTTP cache & de-dupe** across sources; explicit per-domain rate budgets.

### 2) Quality & Verification Layer
- ðŸ§· **Span-grounding:** Store character offsets for each extracted rule.
- ðŸ§‘â€âš–ï¸ **Referee LLM:** Verify rule â†” evidence alignment before normalization.
- ðŸ§¹ **Strategy linter:** Schema completeness, parameter sanity, indicator validation via Indicators MCP, and anti-lookahead checks.
- ðŸŽšï¸ **Confidence model:** Score using evidence types, span coverage, source reputation, and extraction clarity.

### 3) Backtesting Loop (Closed-Loop)
- ðŸ§© **Generator handoff:** Feed normalized JSON to Strategy Generator MCP, then Backtester MCP.
- ðŸ§ª **Micro-backtests:** Small OOS grid (symbols/timeframes/rolling windows). Capture Sharpe/CAGR/maxDD/tail/hit-rate/exposure.
- ðŸ—‚ï¸ **Attach results:** Persist evaluation blocks inside `research://normalized/*` and leaderboard summary in `research://results/*`.
- ðŸ… **Auto-ranking:** Robust metrics (e.g., ProbSharpe, underwater time) with complexity/overfit penalties.

### 4) Retrieval & Re-querying Intelligence
- ðŸ—‚ï¸ **Local paper index (RAG):** Embed abstracts/sections; cross-encoder reranker; query by indicator combos & failure modes.
- ðŸŽ¯ **Active search:** Underperformers trigger targeted re-search (e.g., â€œRSI divergence crypto drawdown mitigationâ€).
- ðŸ§¬ **Synonym expansion:** Harvest aliases/params/default thresholds from Indicators MCP to bias prompts and rules.

### 5) Human-in-the-Loop UX
- ðŸ“Š **Research dashboard:** Queue of candidates with spans, rule diffs, quick backtest sparklines, vote/notes.
- âœï¸ **Inline editor:** Fix rules/params â†’ round-trip normalized JSON; versioned.
- ðŸ§° **Curation dataset:** Every accept/reject/edit becomes training data for extractors and rerankers.

### 6) Ops, Packaging, and Safety
- ðŸ“¦ **Containerize** servers; compose with LangGraph; `.env` templates.
- âœ… **CI/CD:** unit + contract tests for tools; live smoke with VCR cassettes for arXiv/SSRN.
- ðŸ‘€ **Observability:** structured logs, timings, extraction pass rate, dedup ratio, error tags.
- âš–ï¸ **Licensing & ethics:** Store `license`, `robots` decision, and â€œcommercial use safe?â€ flag per doc.
- ðŸ§ª **Schema evolution:** versioned `strategy.v*`; migrations + compatibility checks.

### 7) Model Strategy (Local-first, Optional Cloud)
- ðŸ§  **Extractor ensemble:** Default local (Qwen 14B); â€œrefereeâ€ (Llama 3.1 8B) for span checks; optional cloud flag for tough pages.
- ðŸª„ **Reranker:** Lightweight local cross-encoder (e.g., bge-reranker) for section selection before extraction.
- ðŸ§¾ **Few-shot bank:** Curated TA exemplars by indicator family (RSI/MACD/ATR/Bollinger/Volume). Auto-pick by detected indicators.

### 8) Productize the Dataset
- ðŸ§Š **Snapshots:** Export `normalized` + `results` to S3/Drive with checksums.
- ðŸ”Ž **Searchable catalogue:** Web UI filters (indicator set, timeframe, asset class, metric thresholds).
- ðŸ§­ **Release process:** Semantic versioning + changelog; reproducible seeds recorded.

---

## ðŸ“ Current Capabilities (v0.1 Snapshot)

**Servers:** Indicators MCP (unchanged) + Strategy Research MCP  
**Discovery:** arXiv (API fast-path), SSRN & IDEAS (Brave allowlists)  
**Fetcher:** robots-aware; HTML/PDF â‡’ text; persists `research://raw/*`  
**Extractor:** LangChain + OllamaLLM; chunking + cross-chunk dedup; synonyms via `llm_hint`  
**Normalizer:** Canonicalizes indicators; stringifies structured rules (e.g., `trailing_stop(ATR, multiple=2.0)`); coerces sources/backtest_hints; validates against `strategy.v1`  
**Storage:** `research://normalized/*`, `research://results/*` with near-duplicate pruning

```text
         +----------------+       +-------------------+       +------------------+
         |  Indicators    |       | Strategy Research |       |  Backtester/     |
         |     MCP        |       |       MCP         |       |  Generator MCPs  |
         +--------+-------+       +-----+------+------+       +---------+--------+
                  |                     |      |                        |
                  | list indicators     |      | normalize/save         |
                  | + synonyms          |      | bundle                 |
                  v                     v      v                        |
             +---------+       +-----------------------+                |
             | Search  |-----> | fetch â†’ extract â†’     |                |
             | (arXiv/ |       | normalize â†’ dedup     |------> backtest/results
             | SSRN/   |       +-----------------------+                |
             | IDEAS)  |                                               v
             +---------+                                      +------------------+
                                                             | Ranking & Review |
                                                             +------------------+
```

---

## ðŸ“Š KPIs to Track

- âœ… **Extraction pass rate** (valid schema / total pages)
- ðŸ“Ž **Grounding coverage** (% rules with evidence spans)
- â™»ï¸ **Duplicate rate** pre/post dedup
- ðŸƒ **Backtest throughput** (strategies/day) & **win-rate** vs baselines
- â±ï¸ **Time-to-insight** (doc fetch â†’ ranked result)
- ðŸ› ï¸ **Human correction rate** (lower is better)

---

## ðŸ§© Decisions to Make Now

1) **Source policy:** Which blogs/forums are â€œinâ€ vs â€œoutâ€ (licensing + quality)?  
2) **Backtest budget:** What micro-grid (symbols/timeframes) is acceptable daily?  
3) **Confidence cutline:** Minimum score to auto-queue for backtesting?  
4) **Storage backend:** Remain filesystem or promote to SQLite/Parquet + tiny index?

---

## ðŸ Quick Next Actions

- ðŸ§· Implement **span-grounding** & the **referee LLM** gate.
- ðŸ•¸ï¸ Add **curated blog adapters** (with robots/licensing metadata).
- ðŸ§ª Wire the **backtesting loop** (micro-grid + leaderboard) and attach results to artifacts.
- ðŸ§° Stand up a **minimal dashboard** (spans, diffs, backtest sparkline, approve/reject).
- ðŸ§± Add **contract tests** for tools + VCR-smoked live sources.

> When youâ€™re ready, I can scaffold the LangGraph orchestrator skeleton that runs: _discover â†’ fetch â†’ extract â†’ normalize â†’ verify â†’ backtest â†’ rank â†’ bundle_.

---

### ðŸ”§ Env Knobs (for reference)

- **Models:** `OLLAMA_MODEL` (default `qwen2.5:14b-instruct`), `OLLAMA_MODEL_FALLBACK` (`llama3.1:8b-instruct`)
- **Chunking/Dedup:** `RESEARCH_CHUNK_SIZE_CHARS`, `RESEARCH_CHUNK_OVERLAP_CHARS`, `RESEARCH_MAX_CHUNKS`, `RESEARCH_MAX_CANDIDATES`
- **Search:** `BRAVE_API_KEY` (for SSRN/IDEAS), arXiv needs none
- **Fetcher:** `RESEARCH_USER_AGENT` (robots-aware politeness)

---

*Version: v0.1 roadmap, generated for Strategy Research MCP.*
